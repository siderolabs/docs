---
title: "IRSA with Talos Linux"
description: "How to enable IAM Roles for Service Accounts (IRSA) on Talos Linux."
---

This guide explains how to implement IAM Roles for Service Accounts (IRSA) for a Kubernetes cluster on Talos Linux. This allows Pods to access AWS services using temporary IAM credentials, similar to how EKS clusters in AWS function.

While this example uses AWS S3 and Terraform, the general principles can be applied to any S3-compatible object store and adapted for other infrastructure-as-code tools or a manual setup. For the purpose of this guide, we will create a generic, read-only IRSA Role to test access to S3 from Talos Linux after the IRSA setup is complete. Administrators will need to create their own IAM Roles that target the specific AWS services they need to access from their Kubernetes Pods.

## Prerequisites

Before you begin, you will need:

- A Kubernetes cluster running on Talos Linux.
- An AWS account with permissions to create S3 buckets, IAM roles, and OIDC providers.
- `git`, `ssh-keygen`, `go`, `kubectl`, `helm`, and `aws-cli` installed locally.
- [Terraform](https://www.terraform.io/) (optional, for the examples provided).

This guide is based on the official instructions for setting up the [Amazon EKS Pod Identity Webhook in a self-hosted environment](https://github.com/aws/amazon-eks-pod-identity-webhook/blob/master/SELF_HOSTED_SETUP.md).

## Step 1: Create OIDC serving infrastructure
The following Terraform module creates all the AWS infrastructure needed. You can instantiate this module in your terraform using `source`, or apply it using a `.tfvars` file or command-line flags.

```hcl
# To get IRSA working on an onprem kubernetes, we need to make our cluster an OIDC issuer.
#
# To do this, we create a key pair. An S3 bucket is populated with OIDC discovery params,
#   which includes the public key. This is publicly accessible and registered as an IdP
#   in AWS IAM.
# The private key is known by the apiserver, and used to sign the projected service account
#   tokens. This token is passed by the pod with the IAM role it wishes to assume to AWS,
#   which uses the registered IdP to validate it.
#
# JWKS format:
#   The JWKS RFC shows the expected fields and encodings.
#   Key ID logic comes from https://github.com/kubernetes/kubernetes/pull/78502
#
# Resources:
# * https://docs.siderolabs.com/talos/v1.12/security/iam-roles-for-service-accounts
# * https://github.com/aws/amazon-eks-pod-identity-webhook/blob/master/SELF_HOSTED_SETUP.md
# * https://auth0.com/docs/secure/tokens/json-web-tokens/json-web-key-set-properties
# * https://datatracker.ietf.org/doc/html/rfc7517
# * https://datatracker.ietf.org/doc/html/rfc4648#section-5
# * https://github.com/aws/amazon-eks-pod-identity-webhook/blob/66e63d4532a75c2fb19fa2cea8c0144a5129e48d/hack/self-hosted/main.go

variable "bucket_name" {
  type = string
}

variable "cluster_name" {
  type = string
}

variable "secret_prefix" {
  type = string
}

locals {
  issuer_hostpath = "s3.${data.aws_region.current.region}.amazonaws.com/${var.bucket_name}"
  openid_configuration = jsonencode({
    issuer                                = "https://${local.issuer_hostpath}"
    jwks_uri                              = "https://${local.issuer_hostpath}/keys.json"
    authorization_endpoint                = "urn:kubernetes:programmatic_authorization"
    response_types_supported              = ["id_token"]
    subject_types_supported               = ["public"]
    id_token_signing_alg_values_supported = ["RS256"]
    claims_supported                      = ["sub", "iss"]
  })


  jwks = jsonencode({
    keys = [
      {
        use = "sig"
        alg = "RS256"
        kty = "RSA"
        kid = data.external.pub_der.result.der
        n   = data.external.modulus.result.modulus
        e   = "AQAB"
    }]
  })
}

data "aws_region" "current" {}
data "aws_caller_identity" "current" {}

# generate a key pair that will be used to sign projected service account tokens
resource "tls_private_key" "key" {
  algorithm = "RSA"
  rsa_bits  = 2048
}

# this needs to go into talos machine configuration under cluster.serviceAccount.key
resource "aws_secretsmanager_secret" "signing_key" {
  name = "${var.secret_prefix}/${var.cluster_name}"
}

resource "aws_secretsmanager_secret_version" "signing_key" {
  secret_id     = aws_secretsmanager_secret.signing_key.id
  secret_string = base64encode(tls_private_key.key.private_key_pem)
}

# bucket that we're using as an OIDC discovery endpoint
resource "aws_s3_bucket" "oidc" {
  bucket = var.bucket_name
}

# registering the public bucket host as an IdP
resource "aws_iam_openid_connect_provider" "oidc" {
  url             = "https://${local.issuer_hostpath}"
  client_id_list  = ["sts.amazonaws.com"]
  thumbprint_list = [data.tls_certificate.oidc.certificates[0].sha1_fingerprint]
}

resource "aws_s3_bucket_ownership_controls" "oidc" {
  bucket = aws_s3_bucket.oidc.id
  rule {
    object_ownership = "BucketOwnerPreferred"
  }
}

# we _want_ this bucket to have publicly accessible files
resource "aws_s3_bucket_public_access_block" "oidc" {
  bucket = aws_s3_bucket.oidc.id

  block_public_acls = false
  block_public_policy = false
  ignore_public_acls = false
  restrict_public_buckets = false
}

# the two files we need to serve
resource "aws_s3_object" "keys_json" {
  bucket  = aws_s3_bucket.oidc.id
  key     = "keys.json"
  content = local.jwks
  acl     = "public-read"

  etag = md5(local.jwks)

  depends_on = [
    aws_s3_bucket_ownership_controls.oidc,
    aws_s3_bucket_public_access_block.oidc,
  ]
}

resource "aws_s3_object" "openid-configuration" {
  bucket  = aws_s3_bucket.oidc.id
  key     = ".well-known/openid-configuration"
  content = local.openid_configuration
  acl     = "public-read"

  etag = md5(local.openid_configuration)

  depends_on = [
    aws_s3_bucket_ownership_controls.oidc,
    aws_s3_bucket_public_access_block.oidc,
  ]
}

data "tls_certificate" "oidc" {
  url = "https://${local.issuer_hostpath}"
}

data "external" "pub_der" {
  program = ["bash", "-c", <<EOF
set -euo pipefail
pem=$(jq -r .pem)
der=$(echo "$pem" | openssl pkey -pubin -inform PEM -outform DER | openssl dgst -sha256 -binary | base64 | tr -d '=' | tr '/+' '_-')
jq -n --arg der "$der" '{"der":$der}'
EOF
  ]
  query = { pem = tls_private_key.key.public_key_pem }
}

data "external" "modulus" {
  program = ["bash", "-c", <<EOF
set -euo pipefail
pem=$(jq -r .pem)
modulus=$(echo "$pem" | openssl rsa -inform PEM -modulus -noout | cut -d'=' -f2 | xxd -r -p | base64 | tr -d '=' | tr '/+' '_-')
jq -n --arg modulus "$modulus" '{"modulus":$modulus}'
EOF
  ]
  query = { pem = tls_private_key.key.private_key_pem }
}
```

## Step 2: Configure Talos `machineconfig`

Patch your Talos `machineconfig` to use the new Service Account issuer and signing key.

1.  Create the patch file, `machineconfig-patch.yaml`, fetching `BASE64_ENCODED_PRIVATE_KEY` from AWS SecretsManager as populated by the above module4:

    ```bash
    cat <<EOF > machineconfig-patch.yaml
    cluster:
      apiServer:
        extraArgs:
          service-account-issuer: ${ISSUER_HOSTPATH}
      serviceAccount:
        key: ${BASE64_ENCODED_PRIVATE_KEY}
    EOF
    ```

2.  Apply the patch to your Talos configuration and update your cluster. For example, using `talosctl`:

    ```bash
    talosctl apply-config --nodes <NODE_IP> --file machineconfig-patch.yaml
    ```

3.  Export your `kubeconfig` and `talosconfig` for the updated cluster.

## Step 3: Install Required Kubernetes Components

Two components are required on the cluster: `cert-manager` and `amazon-eks-pod-identity-webhook`.

### Install `cert-manager`

1.  Add the Jetstack Helm repository:

    ```bash
    helm repo add jetstack https://charts.jetstack.io
    helm repo update
    ```

2.  Install the `cert-manager` Helm chart:

    ```bash
    helm install cert-manager jetstack/cert-manager \
      --namespace cert-manager \
      --set crds.enabled=true \
      --create-namespace
    ```

Next, install the `amazon-eks-pod-identity-webhook`.

### Install `amazon-eks-pod-identity-webhook`

1.  Add the `jkroepke` Helm repository:

    ```bash
    helm repo add jkroepke https://jkroepke.github.io/helm-charts/
    helm repo update
    ```

2.  Install the `amazon-eks-pod-identity-webhook` Helm chart:

    ```bash
    helm install amazon-eks-pod-identity-webhook jkroepke/amazon-eks-pod-identity-webhook \
      --namespace kube-system \
      set config.defaultAwsRegion=${AWS_REGION}
    ```

## Step 4: Test AWS S3 Access

We'll test out the setup by creating an AWS role with read access to S3 and a service account, and launch a pod that should be able to assume this role.

1.  Apply this terraform (or create it manually)

    ```hcl
    resource "aws_iam_role" "talos_irsa_s3_readonly_example" {
      name = var.service_account_name
      assume_role_policy = jsonencode({
        Version = "2012-10-17"
        Statement = [
          {
            Action = "sts:AssumeRoleWithWebIdentity"
            Effect = "Allow"
            Sid    = ""
            Principal = {
              Federated = "arn:aws:iam::${var.aws_account_id}:oidc-provider/${var.issuer_hostname}"
            }
            Condition = {
              StringEquals = {
                "${var.s3_bucket_name}:aud": "sts.amazonaws.com",
                "${var.s3_bucket_name}:sub": "system:serviceaccount:${var.namespace}:${var.service_account_name}"
              }
            }
          }
        ]
      })
    }
    
    resource "aws_iam_role_policy_attachment" "talos_irsa_s3_readonly_example" {
      role       = aws_iam_role.talos_irsa_s3_readonly_example.name
      policy_arn = "arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess"
    }
    ```
2.  Create a manifest for the `ServiceAccount` and a test `Pod`. The command below uses a `heredoc` to create `test-pod.yaml` and substitute the shell variables.

    ```bash
    cat <<EOF > test-pod.yaml
    ---
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: ${SERVICEACCOUNT_NAME}
      namespace: ${NAMESPACE}
      annotations:
        eks.amazonaws.com/role-arn: "arn:aws:iam::${AWS_ACCOUNT}:role/${SERVICEACCOUNT_NAME}"
        eks.amazonaws.com/sts-regional-endpoints: "true"
        eks.amazonaws.com/token-expiration: "86400"
    ---
    apiVersion: v1
    kind: Pod
    metadata:
      namespace: ${NAMESPACE}
      name: aws-cli
    spec:
      serviceAccountName: ${SERVICEACCOUNT_NAME}
      containers:
        - name: aws-cli
          image: amazon/aws-cli:latest
          command: ["sleep", "infinity"]
    EOF
    ```

3.  Apply the manifest:

    ```bash
    kubectl apply -f test-pod.yaml
    ```

4.  Exec into the `aws-cli` `Pod`.and test access by listing S3 buckets:

    ```bash
    kubectl exec -it aws-cli -n ${NAMESPACE} -- aws s3 ls
    ```

    This command should list the S3 buckets in your AWS account, confirming that IRSA is correctly configured.
